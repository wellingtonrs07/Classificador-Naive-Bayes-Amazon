{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Venâncio Freitas de Araújo Filho\n",
    "\n",
    "Nome: WELLINGTON RODRIGUES DA SILVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importando as Bibliotecas e fazendo um reconhecimentos das bases de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\venan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\venan\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Materias 2° semestre Insper\\Ciência de dados\\Projetos\\Classificador-Naive-Bayes-Amazon\\Código_Venâncio\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Treino: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muito erros grosseiros de tradução. O material...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primeiramente meu pedido nem veio,Mas me reemb...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Livro com um monte de clichês, mas com pouco c...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sim.adorei o livro Vou continuar a comprar o r...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não recebi o livro . Não sei o motivo. Foi fei...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>O livro foi classificado como novo no site e c...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Não gostei porquê a capa veio com um rasgo, o ...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Não consigo entender o alto valor desses e-boo...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>a caixa veio rasgada e amassada, gostaria de u...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem   Target\n",
       "0    Muito erros grosseiros de tradução. O material...  Editora\n",
       "1    Primeiramente meu pedido nem veio,Mas me reemb...   Amazon\n",
       "2    Livro com um monte de clichês, mas com pouco c...  Editora\n",
       "3    Sim.adorei o livro Vou continuar a comprar o r...  Editora\n",
       "4    Não recebi o livro . Não sei o motivo. Foi fei...   Amazon\n",
       "..                                                 ...      ...\n",
       "293  O livro foi classificado como novo no site e c...   Amazon\n",
       "294  Não gostei porquê a capa veio com um rasgo, o ...   Amazon\n",
       "295  EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...   Amazon\n",
       "296  Não consigo entender o alto valor desses e-boo...   Amazon\n",
       "297  a caixa veio rasgada e amassada, gostaria de u...   Amazon\n",
       "\n",
       "[298 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avaliando a Proporção dos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autor      0.377\n",
       "Editora    0.311\n",
       "Amazon     0.311\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Target.value_counts(True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amontoado de proposições absurdas destinadas a...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quando comprei esse livro fui com uma grande e...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Li um terço do livro. Arrastei-me para procura...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sensacionalista, raso e cheio de distorções ma...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A mensagem do livro da pra entender em 1 págin...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Target\n",
       "0  Amontoado de proposições absurdas destinadas a...  Autor\n",
       "1  Quando comprei esse livro fui com uma grande e...  Autor\n",
       "2  Li um terço do livro. Arrastei-me para procura...  Autor\n",
       "3  Sensacionalista, raso e cheio de distorções ma...  Autor\n",
       "4  A mensagem do livro da pra entender em 1 págin...  Autor"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analisando a proporção dos valores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autor      102\n",
       "Editora     76\n",
       "Amazon      33\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Autor\n",
       "1      Autor\n",
       "2      Autor\n",
       "3      Autor\n",
       "4      Autor\n",
       "       ...  \n",
       "206    Autor\n",
       "207    Autor\n",
       "208    Autor\n",
       "209    Autor\n",
       "210    Autor\n",
       "Name: Target, Length: 211, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Desenvolvimento de Metodologia\n",
    "\n",
    "Tendo em vista que a tarefa submetida tange o treinamento do bot para a classificação das mensagens de acordo com as palavras envolvidas, o grupo identificou como relevante treinar o robô para, a partir das palavras envolvidas na mensagem, identificar para quais grupos seria adequado encaminhar a mensagem. Assim, utilizou-se de 3 formas de classificação: \n",
    "\n",
    "\n",
    "\n",
    "- Amazon: Mensagens relacionadas ao serviço oferecido pela Plataforma; \n",
    "- Editora: Mensagens relacionadas aos serviços prestados pela editora; \n",
    "- Autor: Mensagens relacionadas aos serviços prestados pelo autor ao livro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "- Nesta etapa, vamos iniciar mostrando os rótulos e às frequências referentes à cada rótulo para o classificador, afim de treiná-lo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Vamos Iniciar Extraindo os Dados Referente à cada rótulo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Funções de limpeza do texto: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função CleanUp 1 : Retirada de pontuações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[´\"!-.:?;$'']' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Clean UP 2: Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steamming(texto): #Recebe lista \n",
    "    stemmed_palavras = []\n",
    "    stemmer = PorterStemmer()\n",
    "    for palavra in texto:\n",
    "        \n",
    "        stemmed_palavras.append(stemmer.stem(palavra)) \n",
    "    \n",
    "    return stemmed_palavras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Clean UP 3: Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords2(texto): #Recebe lista \n",
    "    palavras_sem_stopwords = []\n",
    "    palavras = word_tokenize(' '.join(texto), language='portuguese')\n",
    "\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    for palavra in palavras:\n",
    "        if palavra not in stopwords_pt:\n",
    "            palavras_sem_stopwords.append(palavra)\n",
    "    \n",
    "    return palavras_sem_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Clean UP 4:  Remoção de Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(texto): #Recebe lista \n",
    "    texto = ' '.join(texto)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # Símbolos e pictogramas diversos\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # Símbolos alquímicos\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Símbolos de palavras\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Símbolos de árabes estendidos-A\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Símbolos suplementares de árabes estendidos-B\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Símbolos de xadrez\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Símbolos suplementares de xadrez\n",
    "                           u\"\\U0001F004-\\U0001F0CF\"  # Símbolos de domino\n",
    "                           u\"\\U0001F170-\\U0001F251\"  # Símbolos de tai-xi\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # Símbolos e pictogramas diversos\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # Transporte e mapas\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # Símbolos alquímicos\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Símbolos de palavras\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Símbolos de árabes estendidos-A\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Símbolos de xadrez\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Símbolos suplementares de xadrez\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    emoji_pattern = emoji_pattern.sub(r'', texto)\n",
    "    emoji_pattern = emoji_pattern.split(' ')\n",
    "    return emoji_pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função 5: Tokenização Por bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texto):\n",
    "    ' '.join(texto)\n",
    "    lista_bigramas = list(bigrams(texto))\n",
    "    return lista_bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciando a extração dos textos referentes aos Rótulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de extração 1: Limpeza do Dataframe: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracao_texto(series): \n",
    "    texto_novo = ''\n",
    "    for linha in series:\n",
    "        texto_novo += linha + ' '\n",
    "    return texto_novo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de Padronização da Extração dos Rótulos: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_rotulo(dataframe , string_rotulo):\n",
    "    dados_rotulo = dataframe.loc[dataframe.Target == string_rotulo , : ]\n",
    "    texto_rotulo = extracao_texto(dados_rotulo.Mensagem)\n",
    "    texto_rotulo = cleanup(texto_rotulo)\n",
    "    texto_rotulo = texto_rotulo.lower()\n",
    "    texto_rotulo = texto_rotulo.split(' ')\n",
    "    texto_rotulo = remove_emojis(texto_rotulo)\n",
    "    #texto_rotulo = stopwords2(texto_rotulo)\n",
    "    texto_rotulo = steamming(texto_rotulo)\n",
    "    #texto_rotulo = tokenize(texto_rotulo)\n",
    "    tabela_rotulo = pd.Series(texto_rotulo)\n",
    "    return [tabela_rotulo , texto_rotulo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tratando dados do Autor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extraindo os dados e implementando as limpezas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6683,)\n"
     ]
    }
   ],
   "source": [
    "#Montando um Texto\n",
    "tabela_autor = transforma_rotulo(train , 'Autor')[0]\n",
    "texto_autor = transforma_rotulo(train , 'Autor')[1]\n",
    "print(tabela_autor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tabela de palavras com frequência absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de             256\n",
       "o              237\n",
       "que            223\n",
       "e              202\n",
       "a              196\n",
       "              ... \n",
       "invençõ          1\n",
       "passaria         1\n",
       "praticament      1\n",
       "apontar          1\n",
       "sentimento       1\n",
       "Length: 1848, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequências Absolutas \n",
    "tabela_autor_abs = tabela_autor.value_counts()\n",
    "tabela_autor_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tabela de palavras com Frequência relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de             0.038306\n",
       "o              0.035463\n",
       "que            0.033368\n",
       "e              0.030226\n",
       "a              0.029328\n",
       "                 ...   \n",
       "invençõ        0.000150\n",
       "passaria       0.000150\n",
       "praticament    0.000150\n",
       "apontar        0.000150\n",
       "sentimento     0.000150\n",
       "Length: 1848, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequências relativas \n",
    "tabela_autor_relativa = tabela_autor.value_counts(True)\n",
    "tabela_autor_relativa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Número de palavras no Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6683"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_autor_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dados da Editora "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extração dos dados da Editora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        muito\n",
      "1         erro\n",
      "2    grosseiro\n",
      "3           de\n",
      "4     tradução\n",
      "dtype: object\n",
      "(4727,)\n"
     ]
    }
   ],
   "source": [
    "tabela_editora = transforma_rotulo(train , 'Editora')[0]\n",
    "texto_editora = transforma_rotulo(train , 'Editora')[1]\n",
    "print(tabela_editora.head())\n",
    "print(tabela_editora.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tabela de frequências absolutas das palavras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de           194\n",
       "a            158\n",
       "o            139\n",
       "que          134\n",
       "e            132\n",
       "            ... \n",
       "avaliação      1\n",
       "reduza         1\n",
       "dezena         1\n",
       "resisti        1\n",
       "frustada       1\n",
       "Length: 1520, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência absoluta\n",
    "tabela_editora_abs = tabela_editora.value_counts()\n",
    "tabela_editora_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tabela de Frequências relativas das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de           0.041041\n",
       "a            0.033425\n",
       "o            0.029406\n",
       "que          0.028348\n",
       "e            0.027925\n",
       "               ...   \n",
       "avaliação    0.000212\n",
       "reduza       0.000212\n",
       "dezena       0.000212\n",
       "resisti      0.000212\n",
       "frustada     0.000212\n",
       "Length: 1520, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência Relativa \n",
    "tabela_editora_relativa = tabela_editora.value_counts(True)\n",
    "tabela_editora_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4727"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de palavras \n",
    "tabela_editora_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dados da Amazon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extraindo os dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4691,)\n"
     ]
    }
   ],
   "source": [
    "tabela_amazon = transforma_rotulo(train , 'Amazon')[0]\n",
    "texto_amazon = transforma_rotulo(train , 'Amazon')[1]\n",
    "print(tabela_amazon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Frequências absolutas das palavras:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o              177\n",
       "a              157\n",
       "e              143\n",
       "que            129\n",
       "de             104\n",
       "              ... \n",
       "cópia            1\n",
       "enviada          1\n",
       "lamppm           1\n",
       "responsável      1\n",
       "otimo            1\n",
       "Length: 1280, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência absoluta \n",
    "tabela_amazon_abs = tabela_amazon.value_counts()\n",
    "tabela_amazon_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Frequência relativa das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o              0.037732\n",
       "a              0.033468\n",
       "e              0.030484\n",
       "que            0.027499\n",
       "de             0.022170\n",
       "                 ...   \n",
       "cópia          0.000213\n",
       "enviada        0.000213\n",
       "lamppm         0.000213\n",
       "responsável    0.000213\n",
       "otimo          0.000213\n",
       "Length: 1280, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência relativa\n",
    "tabela_amazon_relativa = tabela_amazon.value_counts(True)\n",
    "tabela_amazon_relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Número de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4691"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_amazon_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Construindo o Classificador a partir dos testes\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_sem_repetição(lista_palavras_totais):\n",
    "    lista_sem_repeticao = []\n",
    "    for palavras in lista_palavras_totais: \n",
    "        if palavras not in lista_sem_repeticao:\n",
    "            lista_sem_repeticao.append(palavras)\n",
    "    return lista_sem_repeticao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3347"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todas_palavras = texto_editora + texto_amazon + texto_autor\n",
    "lista_sem_repeticao = lista_sem_repetição(todas_palavras)\n",
    "len(lista_sem_repeticao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Probabilidade de Cada Rótulo dentro do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_rotulo(lista_todas_palavras , tabela_rotulos):\n",
    "    probabilidade = sum(tabela_rotulos) / len(lista_todas_palavras)\n",
    "    return probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41506738711881247"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Autor = prob_rotulo(todas_palavras , tabela_autor_abs)\n",
    "P_Autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.291348363455686"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Amazon = prob_rotulo(todas_palavras , tabela_amazon_abs)\n",
    "P_Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29358424942550154"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Editora = prob_rotulo(todas_palavras , tabela_editora_abs)\n",
    "P_Editora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Probabilidade de aparecer em cada frase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função da Suavização "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suavizacao(frase_linha , tabela_frequencia_abs , alpha , lista_sem_repetição , lista_palavras_rotulos):\n",
    "    P_frase_dado_rótulo = 1 \n",
    "    for palavra in frase_linha: \n",
    "        if palavra in lista_palavras_rotulos: \n",
    "            P_frase_dado_rótulo *= (tabela_frequencia_abs[palavra] + alpha)/ ( (len(lista_sem_repeticao) * alpha) + len(lista_palavras_rotulos))\n",
    "        else: \n",
    "            P_frase_dado_rótulo *= alpha/(len(lista_palavras_rotulos) +(len(lista_sem_repeticao)* alpha))\n",
    "    return P_frase_dado_rótulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vencedor (lista_probs):\n",
    "    if max(lista_probs) == lista_probs[0]:\n",
    "        return 'Autor'\n",
    "    elif max(lista_probs) == lista_probs[1]:\n",
    "        return 'Editora'\n",
    "    elif max(lista_probs) == lista_probs[2]:\n",
    "        return 'Amazon'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_bot(dataframe , alpha):\n",
    "    P_frase_dado_autor = 1\n",
    "    P_frase_dado_editora = 1\n",
    "    P_frase_dado_amazon = 1\n",
    "    lista_teste = []\n",
    "    lista_probs = []\n",
    "    for frase in dataframe.Mensagem:\n",
    "        #CleanUps\n",
    "        frase = cleanup(str(frase))\n",
    "        frase = frase.lower()\n",
    "        frase = frase.split(' ')\n",
    "        frase = remove_emojis(frase)\n",
    "        frase = steamming(frase)\n",
    "        \n",
    "        #Probabilidade de frase dado rótulo\n",
    "        P_frase_dado_autor = suavizacao(frase , tabela_autor_abs , 1 , lista_sem_repeticao , texto_autor)\n",
    "        P_frase_dado_editora = suavizacao(frase , tabela_editora_abs , 1 , lista_sem_repeticao , texto_editora)    \n",
    "        P_frase_dado_amazon = suavizacao(frase, tabela_amazon_abs , 1 , lista_sem_repeticao , texto_amazon) \n",
    "        \n",
    "        #Probabilidade de rótulo dado frase         \n",
    "        P_autor_dado_frase = P_frase_dado_autor * P_Autor\n",
    "        lista_probs.append( P_autor_dado_frase)\n",
    "    \n",
    "        P_editora_dado_frase = P_frase_dado_editora * P_Editora\n",
    "        lista_probs.append( P_editora_dado_frase)\n",
    "    \n",
    "        P_amazon_dado_frase =  P_frase_dado_amazon * P_Amazon\n",
    "        lista_probs.append( P_amazon_dado_frase)\n",
    "        \n",
    "        #Definindo o resultado do Robô\n",
    "        maior = vencedor(lista_probs)\n",
    "        lista_teste.append(maior)\n",
    "    \n",
    "        #Reiniciando as variáveis \n",
    "        P_frase_dado_editora = 1\n",
    "        P_frase_dado_amazon = 1\n",
    "        P_frase_dado_autor = 1\n",
    "    \n",
    "        P_autor_dado_frase = 1\n",
    "    \n",
    "        P_editora_dado_frase = 1\n",
    "    \n",
    "        P_amazon_dado_frase =  1\n",
    "        lista_probs = []\n",
    "    return lista_teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_teste = loop_bot(test , 1)\n",
    "lista_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agora, Vamos Verificar a Performance do Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando os verdadeiros positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Bot</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Editora</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amazon</th>\n",
       "      <td>14.692</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <td>1.422</td>\n",
       "      <td>44.550</td>\n",
       "      <td>2.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Editora</th>\n",
       "      <td>4.739</td>\n",
       "      <td>21.327</td>\n",
       "      <td>9.953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Bot      Amazon   Autor  Editora\n",
       "Target                          \n",
       "Amazon   14.692   0.474    0.474\n",
       "Autor     1.422  44.550    2.370\n",
       "Editora   4.739  21.327    9.953"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Bot'] = lista_teste\n",
    "tabela_verificação = (pd.crosstab(test.Target , test.Bot , normalize = True )*100).round(3)\n",
    "tabela_verificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando o Robô para diferentes situações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_final = pd.read_excel('planilha_junta.xlsx')\n",
    "dataframe_dividido =train_test_split(dataframe_final , test_size =0.4 , shuffle = True)\n",
    "train_final = dataframe_dividido[0]\n",
    "test_final = dataframe_dividido[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
