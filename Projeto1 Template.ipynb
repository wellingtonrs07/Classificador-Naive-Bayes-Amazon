{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Venâncio Freitas de Araújo Filho\n",
    "\n",
    "Nome: WELLINGTON RODRIGUES DA SILVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\venan\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Materias 2° semestre Insper\\Ciência de dados\\Projeto 1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Treino: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muito erros grosseiros de tradução. O material...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primeiramente meu pedido nem veio,Mas me reemb...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Livro com um monte de clichês, mas com pouco c...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sim.adorei o livro Vou continuar a comprar o r...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não recebi o livro . Não sei o motivo. Foi fei...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>O livro foi classificado como novo no site e c...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Não gostei porquê a capa veio com um rasgo, o ...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Não consigo entender o alto valor desses e-boo...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>a caixa veio rasgada e amassada, gostaria de u...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem   Target\n",
       "0    Muito erros grosseiros de tradução. O material...  Editora\n",
       "1    Primeiramente meu pedido nem veio,Mas me reemb...   Amazon\n",
       "2    Livro com um monte de clichês, mas com pouco c...  Editora\n",
       "3    Sim.adorei o livro Vou continuar a comprar o r...  Editora\n",
       "4    Não recebi o livro . Não sei o motivo. Foi fei...   Amazon\n",
       "..                                                 ...      ...\n",
       "293  O livro foi classificado como novo no site e c...   Amazon\n",
       "294  Não gostei porquê a capa veio com um rasgo, o ...   Amazon\n",
       "295  EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...   Amazon\n",
       "296  Não consigo entender o alto valor desses e-boo...   Amazon\n",
       "297  a caixa veio rasgada e amassada, gostaria de u...   Amazon\n",
       "\n",
       "[298 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autor      0.377\n",
       "Editora    0.311\n",
       "Amazon     0.311\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Target.value_counts(True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amontoado de proposições absurdas destinadas a...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quando comprei esse livro fui com uma grande e...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Li um terço do livro. Arrastei-me para procura...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sensacionalista, raso e cheio de distorções ma...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A mensagem do livro da pra entender em 1 págin...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Target\n",
       "0  Amontoado de proposições absurdas destinadas a...  Autor\n",
       "1  Quando comprei esse livro fui com uma grande e...  Autor\n",
       "2  Li um terço do livro. Arrastei-me para procura...  Autor\n",
       "3  Sensacionalista, raso e cheio de distorções ma...  Autor\n",
       "4  A mensagem do livro da pra entender em 1 págin...  Autor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autor      102\n",
       "Editora     76\n",
       "Amazon      33\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Autor\n",
       "1      Autor\n",
       "2      Autor\n",
       "3      Autor\n",
       "4      Autor\n",
       "       ...  \n",
       "206    Autor\n",
       "207    Autor\n",
       "208    Autor\n",
       "209    Autor\n",
       "210    Autor\n",
       "Name: Target, Length: 211, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o que considerou como relevante ou não relevante na classificação dos tweets (Target).\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Vamos Iniciar Extraindo os Dados Referente à cada rótulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função CleanUp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[´\"!-.:?;$'']' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dados do Autor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Mensagem Target\n",
      "40  Como o livro se concentra na política american...  Autor\n",
      "42  Achei ridículo! Eu realmente esperava uma hist...  Autor\n"
     ]
    }
   ],
   "source": [
    "dados_autor  = train.loc[train.Target == 'Autor' , :]\n",
    "print(dados_autor.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6683,)\n"
     ]
    }
   ],
   "source": [
    "#Montando um Texto\n",
    "texto_comentários_autor = ''\n",
    "for i in dados_autor.Mensagem: \n",
    "    texto_comentários_autor += i\n",
    "    texto_comentários_autor += ' '\n",
    "texto_comentários_autor = cleanup(texto_comentários_autor)\n",
    "texto_comentarios_autor = texto_comentários_autor.lower()\n",
    "texto_comentarios_autor = texto_comentarios_autor.split(' ')\n",
    "tabela_autor = pd.Series(texto_comentarios_autor )\n",
    "tabela_autor.head()\n",
    "print(tabela_autor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabelas Relativas ao autor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequências Absolutas \n",
    "tabela_autor_abs = tabela_autor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de                 0.038306\n",
       "o                  0.035463\n",
       "que                0.033368\n",
       "e                  0.030226\n",
       "a                  0.029328\n",
       "                     ...   \n",
       "passaria           0.000150\n",
       "praticamente       0.000150\n",
       "apontar            0.000150\n",
       "efetivo            0.000150\n",
       "relacionamentos    0.000150\n",
       "Length: 1982, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequências relativas \n",
    "tabela_autor_relativa = tabela_autor.value_counts(True)\n",
    "tabela_autor_relativa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6683"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_autor_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dados da Editora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_editora = train.loc[train.Target == 'Editora' , :]\n",
    "dados_editora.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         muito\n",
      "1         erros\n",
      "2    grosseiros\n",
      "3            de\n",
      "4      tradução\n",
      "dtype: object\n",
      "(4727,)\n"
     ]
    }
   ],
   "source": [
    "comentarios_editora = dados_editora.Mensagem\n",
    "texto_editora = ''\n",
    "for e in comentarios_editora:\n",
    "    texto_editora += e \n",
    "    texto_editora += ' '\n",
    "texto_editora = cleanup(texto_editora)\n",
    "texto_editora = texto_editora.lower()\n",
    "texto_editora = texto_editora.split(' ')\n",
    "tabela_editora = pd.Series(texto_editora)\n",
    "print(tabela_editora.head())\n",
    "print(tabela_editora.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequências relativas às tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequência absoluta\n",
    "tabela_editora_abs = tabela_editora.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de          0.041041\n",
       "a           0.033425\n",
       "o           0.029406\n",
       "que         0.028348\n",
       "e           0.027925\n",
       "              ...   \n",
       "perdemos    0.000212\n",
       "lendo       0.000212\n",
       "viu         0.000212\n",
       "presente    0.000212\n",
       "frustada    0.000212\n",
       "Length: 1617, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência Relativa \n",
    "tabela_editora_relativa = tabela_editora.value_counts(True)\n",
    "tabela_editora_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4727"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de palavras \n",
    "tabela_editora_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Dados da Amazon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Mensagem  Target\n",
      "1    Primeiramente meu pedido nem veio,Mas me reemb...  Amazon\n",
      "4    Não recebi o livro . Não sei o motivo. Foi fei...  Amazon\n",
      "7    Pelo amor de Deus!!!! que preço é este......só...  Amazon\n",
      "12   FiZ a compra errada, era pra comprar o livro e...  Amazon\n",
      "23   Não recebi o livro... Acredito que tenham envi...  Amazon\n",
      "..                                                 ...     ...\n",
      "293  O livro foi classificado como novo no site e c...  Amazon\n",
      "294  Não gostei porquê a capa veio com um rasgo, o ...  Amazon\n",
      "295  EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...  Amazon\n",
      "296  Não consigo entender o alto valor desses e-boo...  Amazon\n",
      "297  a caixa veio rasgada e amassada, gostaria de u...  Amazon\n",
      "\n",
      "[90 rows x 2 columns]\n",
      "(90, 2)\n"
     ]
    }
   ],
   "source": [
    "dados_amazon = train.loc[train.Target == 'Amazon' , :]\n",
    "print(dados_amazon)\n",
    "print(dados_amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       primeiramente\n",
      "1                 meu\n",
      "2              pedido\n",
      "3                 nem\n",
      "4             veiomas\n",
      "            ...      \n",
      "4686            estão\n",
      "4687               em\n",
      "4688            otimo\n",
      "4689           estado\n",
      "4690                 \n",
      "Length: 4691, dtype: object\n"
     ]
    }
   ],
   "source": [
    "comentarios_amazon = dados_amazon.Mensagem\n",
    "texto_amazon = ''\n",
    "for texto in comentarios_amazon:\n",
    "    texto_amazon += texto \n",
    "    texto_amazon += ' '\n",
    "texto_amazon = cleanup(texto_amazon)\n",
    "texto_amazon = texto_amazon.lower()\n",
    "texto_amazon = texto_amazon.split(' ')\n",
    "tabela_amazon = pd.Series(texto_amazon)\n",
    "print(tabela_amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequências referentes à Amazon: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequência absoluta \n",
    "tabela_amazon_abs = tabela_amazon.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o          0.037732\n",
       "a          0.033468\n",
       "e          0.030484\n",
       "que        0.027499\n",
       "de         0.022170\n",
       "             ...   \n",
       "olá        0.000213\n",
       "cópia      0.000213\n",
       "enviada    0.000213\n",
       "lamppm     0.000213\n",
       "otimo      0.000213\n",
       "Length: 1369, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência relativa\n",
    "tabela_amazon_relativa = tabela_amazon.value_counts(True)\n",
    "tabela_amazon_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4691"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_amazon_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Construindo o Classificador a partir dos testes\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras = texto_editora + texto_amazon + texto_comentarios_autor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Probabilidade de Cada Rótulo dentro do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41506738711881247"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Autor = sum(tabela_autor_abs) / len(todas_palavras)\n",
    "P_Autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.291348363455686"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Amazon = sum(tabela_amazon_abs) / len(todas_palavras)\n",
    "P_Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29358424942550154"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Editora = sum(tabela_editora_abs) / len(todas_palavras)\n",
    "P_Editora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Probabilidade de aparecer em cada frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_frase_dado_autor = 1\n",
    "P_frase_dado_editora = 1\n",
    "P_frase_dado_amazon = 1\n",
    "lista_teste = []\n",
    "i = 0\n",
    "lista_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for frase in test.Mensagem:\n",
    "    frase = cleanup(str(frase))\n",
    "    frase = frase.lower()\n",
    "    frase = frase.split()\n",
    "    \n",
    "    for palavras in frase:\n",
    "        \n",
    "        if palavras in texto_comentarios_autor: \n",
    "            P_frase_dado_autor *= tabela_autor_relativa[palavras] + (1/len(tabela_autor))\n",
    "        else: \n",
    "            P_frase_dado_autor *= (1/len(tabela_autor))\n",
    "            \n",
    "        \n",
    "        if palavras in texto_amazon: \n",
    "            P_frase_dado_amazon *= tabela_amazon_relativa[palavras] + (1/len(tabela_amazon))\n",
    "        else: \n",
    "            P_frase_dado_amazon *= (1/len(tabela_amazon))\n",
    "        \n",
    "                \n",
    "        if palavras in texto_editora: \n",
    "            P_frase_dado_editora *= tabela_editora_relativa[palavras] + (1/len(tabela_editora))\n",
    "        else: \n",
    "            P_frase_dado_editora *= (1/len(tabela_editora))\n",
    "            \n",
    "        \n",
    "            \n",
    "    P_autor_dado_frase = P_frase_dado_autor * P_Autor\n",
    "    lista_probs.append( P_autor_dado_frase)\n",
    "    \n",
    "    P_editora_dado_frase = P_frase_dado_editora * P_Editora\n",
    "    lista_probs.append( P_editora_dado_frase)\n",
    "    \n",
    "    P_amazon_dado_frase =  P_frase_dado_amazon * P_Amazon\n",
    "    lista_probs.append( P_amazon_dado_frase)\n",
    "    \n",
    "    if max(lista_probs) == lista_probs[0]:\n",
    "        lista_teste.append('Autor')\n",
    "    elif max(lista_probs) == lista_probs[1]:\n",
    "        lista_teste.append('Editora')\n",
    "    elif max(lista_probs) == lista_probs[2]:\n",
    "        lista_teste.append('Amazon')\n",
    "        \n",
    "    P_frase_dado_editora = 1\n",
    "    P_frase_dado_amazon = 1\n",
    "    P_frase_dado_autor = 1\n",
    "    \n",
    "    P_autor_dado_frase = 1\n",
    "    \n",
    "    P_editora_dado_frase = 1\n",
    "    \n",
    "    P_amazon_dado_frase =  1\n",
    "    lista_probs = []\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "lista_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agora, Vamos Verificar a Performance do Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando os verdadeiros positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Bot</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Editora</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amazon</th>\n",
       "      <td>14.692</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <td>3.791</td>\n",
       "      <td>25.118</td>\n",
       "      <td>19.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Editora</th>\n",
       "      <td>7.109</td>\n",
       "      <td>12.322</td>\n",
       "      <td>16.588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Bot      Amazon   Autor  Editora\n",
       "Target                          \n",
       "Amazon   14.692   0.000    0.948\n",
       "Autor     3.791  25.118   19.431\n",
       "Editora   7.109  12.322   16.588"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Bot'] = lista_teste\n",
    "tabela_verificação = (pd.crosstab(test.Target , test.Bot , normalize = True) * 100).round(3)\n",
    "tabela_verificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando Acertos no Rótulo Autor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando Acertos no Rótulo Editora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando Acertos no Rótulo Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acurácia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agora, Vamos calcular os desvios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    elif P_editora_dado_frase >= P_autor_dado_frase and P_editora_dado_frase >= P_amazon_dado_frase:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "if P_autor_dado_frase >= P_editora_dado_frase and P_autor_dado_frase >= P_amazon_dado_frase:\n",
    "        dicio_treino[i] = 'Autor'\n",
    "        \n",
    "    elif P_editora_dado_frase >= P_autor_dado_frase and P_editora_dado_frase >= P_amazon_dado_frase:\n",
    "        dicio_treino[i] = 'Editora'\n",
    "        \n",
    "    elif P_amazon_dado_frase > P_autor_dado_frase and P_amazon_dado_frase > P_editora_dado_frase: \n",
    "        dicio_treino[i] = 'Amazon'\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
