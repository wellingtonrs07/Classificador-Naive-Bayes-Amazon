{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Venâncio Freitas de Araújo Filho\n",
    "\n",
    "Nome: WELLINGTON RODRIGUES DA SILVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Wellington\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Cdados\\Projeto 1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Treino: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muito erros grosseiros de tradução. O material...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primeiramente meu pedido nem veio,Mas me reemb...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Livro com um monte de clichês, mas com pouco c...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sim.adorei o livro Vou continuar a comprar o r...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>O livro foi classificado como novo no site e c...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Não gostei porquê a capa veio com um rasgo, o ...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Não consigo entender o alto valor desses e-boo...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>a caixa veio rasgada e amassada, gostaria de u...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem   Target\n",
       "0    Muito erros grosseiros de tradução. O material...  Editora\n",
       "1    Primeiramente meu pedido nem veio,Mas me reemb...   Amazon\n",
       "2    Livro com um monte de clichês, mas com pouco c...  Editora\n",
       "3    Sim.adorei o livro Vou continuar a comprar o r...  Editora\n",
       "4                                                  NaN      NaN\n",
       "..                                                 ...      ...\n",
       "309  O livro foi classificado como novo no site e c...   Amazon\n",
       "310  Não gostei porquê a capa veio com um rasgo, o ...   Amazon\n",
       "311  EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...   Amazon\n",
       "312  Não consigo entender o alto valor desses e-boo...   Amazon\n",
       "313  a caixa veio rasgada e amassada, gostaria de u...   Amazon\n",
       "\n",
       "[314 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autor      0.377\n",
       "Editora    0.311\n",
       "Amazon     0.311\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Target.value_counts(True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amontoado de proposições absurdas destinadas a...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quando comprei esse livro fui com uma grande e...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Li um terço do livro. Arrastei-me para procura...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sensacionalista, raso e cheio de distorções ma...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A mensagem do livro da pra entender em 1 págin...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Target\n",
       "0  Amontoado de proposições absurdas destinadas a...  Autor\n",
       "1  Quando comprei esse livro fui com uma grande e...  Autor\n",
       "2  Li um terço do livro. Arrastei-me para procura...  Autor\n",
       "3  Sensacionalista, raso e cheio de distorções ma...  Autor\n",
       "4  A mensagem do livro da pra entender em 1 págin...  Autor"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autor      102\n",
       "Editora     76\n",
       "Amazon      33\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Autor\n",
       "1      Autor\n",
       "2      Autor\n",
       "3      Autor\n",
       "4      Autor\n",
       "       ...  \n",
       "206    Autor\n",
       "207    Autor\n",
       "208    Autor\n",
       "209    Autor\n",
       "210    Autor\n",
       "Name: Target, Length: 211, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o que considerou como relevante ou não relevante na classificação dos tweets (Target).\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Vamos Iniciar Extraindo os Dados Referente à cada rótulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função CleanUp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[´\"!-.:?;$'']' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dados do Autor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Mensagem Target\n",
      "56  Como o livro se concentra na política american...  Autor\n",
      "58  Achei ridículo! Eu realmente esperava uma hist...  Autor\n"
     ]
    }
   ],
   "source": [
    "dados_autor  = train.loc[train.Target == 'Autor' , :]\n",
    "print(dados_autor.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6683,)\n"
     ]
    }
   ],
   "source": [
    "#Montando um Texto\n",
    "texto_comentários_autor = ''\n",
    "for i in dados_autor.Mensagem: \n",
    "    texto_comentários_autor += i\n",
    "    texto_comentários_autor += ' '\n",
    "texto_comentários_autor = cleanup(texto_comentários_autor)\n",
    "texto_comentarios_autor = texto_comentários_autor.lower()\n",
    "texto_comentarios_autor = texto_comentarios_autor.split(' ')\n",
    "tabela_autor = pd.Series(texto_comentarios_autor )\n",
    "tabela_autor.head()\n",
    "print(tabela_autor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabelas Relativas ao autor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequências Absolutas \n",
    "tabela_autor_abs = tabela_autor.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de                 0.038306\n",
       "o                  0.035463\n",
       "que                0.033368\n",
       "e                  0.030226\n",
       "a                  0.029328\n",
       "                     ...   \n",
       "passaria           0.000150\n",
       "praticamente       0.000150\n",
       "apontar            0.000150\n",
       "efetivo            0.000150\n",
       "relacionamentos    0.000150\n",
       "Length: 1982, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequências relativas \n",
    "tabela_autor_relativa = tabela_autor.value_counts(True)\n",
    "tabela_autor_relativa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6683"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_autor_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dados da Editora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_editora = train.loc[train.Target == 'Editora' , :]\n",
    "dados_editora.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         muito\n",
      "1         erros\n",
      "2    grosseiros\n",
      "3            de\n",
      "4      tradução\n",
      "dtype: object\n",
      "(4727,)\n"
     ]
    }
   ],
   "source": [
    "comentarios_editora = dados_editora.Mensagem\n",
    "texto_editora = ''\n",
    "for e in comentarios_editora:\n",
    "    texto_editora += e \n",
    "    texto_editora += ' '\n",
    "texto_editora = cleanup(texto_editora)\n",
    "texto_editora = texto_editora.lower()\n",
    "texto_editora = texto_editora.split(' ')\n",
    "tabela_editora = pd.Series(texto_editora)\n",
    "print(tabela_editora.head())\n",
    "print(tabela_editora.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequências relativas às tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequência absoluta\n",
    "tabela_editora_abs = tabela_editora.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de          0.041041\n",
       "a           0.033425\n",
       "o           0.029406\n",
       "que         0.028348\n",
       "e           0.027925\n",
       "              ...   \n",
       "perdemos    0.000212\n",
       "lendo       0.000212\n",
       "viu         0.000212\n",
       "presente    0.000212\n",
       "frustada    0.000212\n",
       "Length: 1617, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência Relativa \n",
    "tabela_editora_relativa = tabela_editora.value_counts(True)\n",
    "tabela_editora_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4727"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de palavras \n",
    "tabela_editora_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Dados da Amazon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Mensagem  Target\n",
      "1    Primeiramente meu pedido nem veio,Mas me reemb...  Amazon\n",
      "7    Não recebi o livro . Não sei o motivo. Foi fei...  Amazon\n",
      "14   Pelo amor de Deus!!!! que preço é este......só...  Amazon\n",
      "21   FiZ a compra errada, era pra comprar o livro e...  Amazon\n",
      "32   Não recebi o livro... Acredito que tenham envi...  Amazon\n",
      "..                                                 ...     ...\n",
      "309  O livro foi classificado como novo no site e c...  Amazon\n",
      "310  Não gostei porquê a capa veio com um rasgo, o ...  Amazon\n",
      "311  EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...  Amazon\n",
      "312  Não consigo entender o alto valor desses e-boo...  Amazon\n",
      "313  a caixa veio rasgada e amassada, gostaria de u...  Amazon\n",
      "\n",
      "[90 rows x 2 columns]\n",
      "(90, 2)\n"
     ]
    }
   ],
   "source": [
    "dados_amazon = train.loc[train.Target == 'Amazon' , :]\n",
    "print(dados_amazon)\n",
    "print(dados_amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       primeiramente\n",
      "1                 meu\n",
      "2              pedido\n",
      "3                 nem\n",
      "4             veiomas\n",
      "            ...      \n",
      "4686            estão\n",
      "4687               em\n",
      "4688            otimo\n",
      "4689           estado\n",
      "4690                 \n",
      "Length: 4691, dtype: object\n"
     ]
    }
   ],
   "source": [
    "comentarios_amazon = dados_amazon.Mensagem\n",
    "texto_amazon = ''\n",
    "for texto in comentarios_amazon:\n",
    "    texto_amazon += texto \n",
    "    texto_amazon += ' '\n",
    "texto_amazon = cleanup(texto_amazon)\n",
    "texto_amazon = texto_amazon.lower()\n",
    "texto_amazon = texto_amazon.split(' ')\n",
    "tabela_amazon = pd.Series(texto_amazon)\n",
    "print(tabela_amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequências referentes à Amazon: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequência absoluta \n",
    "tabela_amazon_abs = tabela_amazon.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o          0.037732\n",
       "a          0.033468\n",
       "e          0.030484\n",
       "que        0.027499\n",
       "de         0.022170\n",
       "             ...   \n",
       "olá        0.000213\n",
       "cópia      0.000213\n",
       "enviada    0.000213\n",
       "lamppm     0.000213\n",
       "otimo      0.000213\n",
       "Length: 1369, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência relativa\n",
    "tabela_amazon_relativa = tabela_amazon.value_counts(True)\n",
    "tabela_amazon_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4691"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_amazon_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Construindo o Classificador a partir dos testes\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras = texto_editora + texto_amazon + texto_comentarios_autor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Probabilidade de Cada Rótulo dentro do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41506738711881247"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Autor = sum(tabela_autor_abs) / len(todas_palavras)\n",
    "P_Autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.291348363455686"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Amazon = sum(tabela_amazon_abs) / len(todas_palavras)\n",
    "P_Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29358424942550154"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Editora = sum(tabela_editora_abs) / len(todas_palavras)\n",
    "P_Editora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Probabilidade de aparecer em cada frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_frase_dado_autor = 1\n",
    "P_frase_dado_editora = 1\n",
    "P_frase_dado_amazon = 1\n",
    "dicio_treino = {}\n",
    "i = 0\n",
    "lista_probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Editora',\n",
       " 1: 'Autor',\n",
       " 2: 'Autor',\n",
       " 3: 'Autor',\n",
       " 4: 'Autor',\n",
       " 5: 'Autor',\n",
       " 6: 'Autor',\n",
       " 7: 'Autor',\n",
       " 8: 'Autor',\n",
       " 9: 'Autor',\n",
       " 10: 'Autor',\n",
       " 11: 'Editora',\n",
       " 12: 'Autor',\n",
       " 13: 'Autor',\n",
       " 14: 'Autor',\n",
       " 15: 'Editora',\n",
       " 16: 'Autor',\n",
       " 17: 'Autor',\n",
       " 18: 'Autor',\n",
       " 19: 'Autor',\n",
       " 20: 'Autor',\n",
       " 21: 'Amazon',\n",
       " 22: 'Autor',\n",
       " 23: 'Autor',\n",
       " 24: 'Autor',\n",
       " 25: 'Autor',\n",
       " 26: 'Autor',\n",
       " 27: 'Autor',\n",
       " 28: 'Autor',\n",
       " 29: 'Autor',\n",
       " 30: 'Autor',\n",
       " 31: 'Autor',\n",
       " 32: 'Autor',\n",
       " 33: 'Autor',\n",
       " 34: 'Autor',\n",
       " 35: 'Editora',\n",
       " 36: 'Autor',\n",
       " 37: 'Editora',\n",
       " 38: 'Autor',\n",
       " 39: 'Amazon',\n",
       " 40: 'Amazon',\n",
       " 41: 'Autor',\n",
       " 42: 'Autor',\n",
       " 43: 'Autor',\n",
       " 44: 'Autor',\n",
       " 45: 'Amazon',\n",
       " 46: 'Autor',\n",
       " 47: 'Autor',\n",
       " 48: 'Autor',\n",
       " 49: 'Autor',\n",
       " 50: 'Autor',\n",
       " 51: 'Autor',\n",
       " 52: 'Autor',\n",
       " 53: 'Autor',\n",
       " 54: 'Autor',\n",
       " 55: 'Autor',\n",
       " 56: 'Autor',\n",
       " 57: 'Autor',\n",
       " 58: 'Autor',\n",
       " 59: 'Autor',\n",
       " 60: 'Autor',\n",
       " 61: 'Amazon',\n",
       " 62: 'Amazon',\n",
       " 63: 'Autor',\n",
       " 64: 'Editora',\n",
       " 65: 'Autor',\n",
       " 66: 'Amazon',\n",
       " 67: 'Autor',\n",
       " 68: 'Autor',\n",
       " 69: 'Editora',\n",
       " 70: 'Autor',\n",
       " 71: 'Autor',\n",
       " 72: 'Autor',\n",
       " 73: 'Editora',\n",
       " 74: 'Autor',\n",
       " 75: 'Autor',\n",
       " 76: 'Autor',\n",
       " 77: 'Autor',\n",
       " 78: 'Autor',\n",
       " 79: 'Autor',\n",
       " 80: 'Amazon',\n",
       " 81: 'Editora',\n",
       " 82: 'Autor',\n",
       " 83: 'Autor',\n",
       " 84: 'Autor',\n",
       " 85: 'Autor',\n",
       " 86: 'Autor',\n",
       " 87: 'Autor',\n",
       " 88: 'Autor',\n",
       " 89: 'Autor',\n",
       " 90: 'Autor',\n",
       " 91: 'Autor',\n",
       " 92: 'Autor',\n",
       " 93: 'Autor',\n",
       " 94: 'Autor',\n",
       " 95: 'Autor',\n",
       " 96: 'Autor',\n",
       " 97: 'Autor',\n",
       " 98: 'Autor',\n",
       " 99: 'Autor',\n",
       " 100: 'Autor',\n",
       " 101: 'Autor',\n",
       " 102: 'Autor',\n",
       " 103: 'Autor',\n",
       " 104: 'Amazon',\n",
       " 105: 'Autor',\n",
       " 106: 'Autor',\n",
       " 107: 'Editora',\n",
       " 108: 'Amazon',\n",
       " 109: 'Editora',\n",
       " 110: 'Amazon',\n",
       " 111: 'Autor',\n",
       " 112: 'Amazon',\n",
       " 113: 'Amazon',\n",
       " 114: 'Amazon',\n",
       " 115: 'Amazon',\n",
       " 116: 'Amazon',\n",
       " 117: 'Editora',\n",
       " 118: 'Amazon',\n",
       " 119: 'Autor',\n",
       " 120: 'Amazon',\n",
       " 121: 'Autor',\n",
       " 122: 'Amazon',\n",
       " 123: 'Autor',\n",
       " 124: 'Autor',\n",
       " 125: 'Amazon',\n",
       " 126: 'Autor',\n",
       " 127: 'Amazon',\n",
       " 128: 'Autor',\n",
       " 129: 'Autor',\n",
       " 130: 'Autor',\n",
       " 131: 'Autor',\n",
       " 132: 'Editora',\n",
       " 133: 'Autor',\n",
       " 134: 'Autor',\n",
       " 135: 'Autor',\n",
       " 136: 'Autor',\n",
       " 137: 'Autor',\n",
       " 138: 'Amazon',\n",
       " 139: 'Autor',\n",
       " 140: 'Autor',\n",
       " 141: 'Autor',\n",
       " 142: 'Autor',\n",
       " 143: 'Editora',\n",
       " 144: 'Amazon',\n",
       " 145: 'Autor',\n",
       " 146: 'Autor',\n",
       " 147: 'Amazon',\n",
       " 148: 'Editora',\n",
       " 149: 'Amazon',\n",
       " 150: 'Autor',\n",
       " 151: 'Autor',\n",
       " 152: 'Editora',\n",
       " 153: 'Amazon',\n",
       " 154: 'Autor',\n",
       " 155: 'Autor',\n",
       " 156: 'Autor',\n",
       " 157: 'Autor',\n",
       " 158: 'Autor',\n",
       " 159: 'Amazon',\n",
       " 160: 'Editora',\n",
       " 161: 'Autor',\n",
       " 162: 'Autor',\n",
       " 163: 'Amazon',\n",
       " 164: 'Editora',\n",
       " 165: 'Amazon',\n",
       " 166: 'Editora',\n",
       " 167: 'Autor',\n",
       " 168: 'Autor',\n",
       " 169: 'Autor',\n",
       " 170: 'Autor',\n",
       " 171: 'Amazon',\n",
       " 172: 'Amazon',\n",
       " 173: 'Amazon',\n",
       " 174: 'Autor',\n",
       " 175: 'Autor',\n",
       " 176: 'Editora',\n",
       " 177: 'Autor',\n",
       " 178: 'Autor',\n",
       " 179: 'Amazon',\n",
       " 180: 'Autor',\n",
       " 181: 'Autor',\n",
       " 182: 'Autor',\n",
       " 183: 'Autor',\n",
       " 184: 'Editora',\n",
       " 185: 'Autor',\n",
       " 186: 'Autor',\n",
       " 187: 'Autor',\n",
       " 188: 'Autor',\n",
       " 189: 'Amazon',\n",
       " 190: 'Autor',\n",
       " 191: 'Autor',\n",
       " 192: 'Autor',\n",
       " 193: 'Autor',\n",
       " 194: 'Amazon',\n",
       " 195: 'Autor',\n",
       " 196: 'Autor',\n",
       " 197: 'Autor',\n",
       " 198: 'Autor',\n",
       " 199: 'Autor',\n",
       " 200: 'Autor',\n",
       " 201: 'Autor',\n",
       " 202: 'Autor',\n",
       " 203: 'Autor',\n",
       " 204: 'Amazon',\n",
       " 205: 'Autor',\n",
       " 206: 'Amazon',\n",
       " 207: 'Autor',\n",
       " 208: 'Autor',\n",
       " 209: 'Autor',\n",
       " 210: 'Autor',\n",
       " 211: 'Editora',\n",
       " 212: 'Amazon',\n",
       " 213: 'Autor',\n",
       " 214: 'Autor',\n",
       " 215: 'Autor',\n",
       " 216: 'Autor',\n",
       " 217: 'Autor',\n",
       " 218: 'Autor',\n",
       " 219: 'Autor',\n",
       " 220: 'Autor',\n",
       " 221: 'Editora',\n",
       " 222: 'Autor',\n",
       " 223: 'Autor',\n",
       " 224: 'Autor',\n",
       " 225: 'Amazon',\n",
       " 226: 'Amazon',\n",
       " 227: 'Editora',\n",
       " 228: 'Autor',\n",
       " 229: 'Autor',\n",
       " 230: 'Autor',\n",
       " 231: 'Amazon',\n",
       " 232: 'Autor',\n",
       " 233: 'Autor',\n",
       " 234: 'Amazon',\n",
       " 235: 'Autor',\n",
       " 236: 'Autor',\n",
       " 237: 'Autor',\n",
       " 238: 'Autor',\n",
       " 239: 'Autor',\n",
       " 240: 'Autor',\n",
       " 241: 'Autor',\n",
       " 242: 'Autor',\n",
       " 243: 'Autor',\n",
       " 244: 'Autor',\n",
       " 245: 'Autor',\n",
       " 246: 'Autor',\n",
       " 247: 'Autor',\n",
       " 248: 'Autor',\n",
       " 249: 'Autor',\n",
       " 250: 'Amazon',\n",
       " 251: 'Autor',\n",
       " 252: 'Autor',\n",
       " 253: 'Autor',\n",
       " 254: 'Autor',\n",
       " 255: 'Amazon',\n",
       " 256: 'Amazon',\n",
       " 257: 'Autor',\n",
       " 258: 'Autor',\n",
       " 259: 'Amazon',\n",
       " 260: 'Autor',\n",
       " 261: 'Autor',\n",
       " 262: 'Autor',\n",
       " 263: 'Autor',\n",
       " 264: 'Amazon',\n",
       " 265: 'Autor',\n",
       " 266: 'Autor',\n",
       " 267: 'Amazon',\n",
       " 268: 'Amazon',\n",
       " 269: 'Autor',\n",
       " 270: 'Autor',\n",
       " 271: 'Autor',\n",
       " 272: 'Autor',\n",
       " 273: 'Autor',\n",
       " 274: 'Autor',\n",
       " 275: 'Amazon',\n",
       " 276: 'Autor',\n",
       " 277: 'Autor',\n",
       " 278: 'Amazon',\n",
       " 279: 'Autor',\n",
       " 280: 'Autor',\n",
       " 281: 'Autor',\n",
       " 282: 'Autor',\n",
       " 283: 'Amazon',\n",
       " 284: 'Autor',\n",
       " 285: 'Amazon',\n",
       " 286: 'Autor',\n",
       " 287: 'Autor',\n",
       " 288: 'Autor',\n",
       " 289: 'Amazon',\n",
       " 290: 'Autor',\n",
       " 291: 'Editora',\n",
       " 292: 'Autor',\n",
       " 293: 'Autor',\n",
       " 294: 'Autor',\n",
       " 295: 'Autor',\n",
       " 296: 'Autor',\n",
       " 297: 'Amazon',\n",
       " 298: 'Amazon',\n",
       " 299: 'Amazon',\n",
       " 300: 'Amazon',\n",
       " 301: 'Autor',\n",
       " 302: 'Autor',\n",
       " 303: 'Autor',\n",
       " 304: 'Amazon',\n",
       " 305: 'Autor',\n",
       " 306: 'Amazon',\n",
       " 307: 'Amazon',\n",
       " 308: 'Autor',\n",
       " 309: 'Autor',\n",
       " 310: 'Autor',\n",
       " 311: 'Amazon',\n",
       " 312: 'Amazon',\n",
       " 313: 'Autor'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for frase in train.Mensagem:\n",
    "    frase = cleanup(str(frase))\n",
    "    frase = frase.lower()\n",
    "    frase = frase.split()\n",
    "    \n",
    "    for palavras in frase:\n",
    "        \n",
    "        if palavras in texto_comentarios_autor: \n",
    "            P_frase_dado_autor *= tabela_autor_relativa[palavras] + (1/len(frase))\n",
    "        else: \n",
    "            P_frase_dado_autor *= (1/len(frase))\n",
    "            \n",
    "        \n",
    "        if palavras in texto_amazon: \n",
    "            P_frase_dado_amazon *= tabela_amazon_relativa[palavras] + (1/len(frase))\n",
    "        else: \n",
    "            P_frase_dado_amazon *= (1/len(frase))\n",
    "        \n",
    "                \n",
    "        if palavras in texto_editora: \n",
    "            P_frase_dado_editora *= tabela_editora_relativa[palavras] + (1/len(frase))\n",
    "        else: \n",
    "            P_frase_dado_editora *= (1/len(frase))\n",
    "            \n",
    "        \n",
    "            \n",
    "    P_autor_dado_frase = P_frase_dado_autor * P_Autor\n",
    "    lista_probs.append( P_autor_dado_frase)\n",
    "    \n",
    "    P_editora_dado_frase = P_frase_dado_editora * P_Editora\n",
    "    lista_probs.append( P_editora_dado_frase)\n",
    "    \n",
    "    P_amazon_dado_frase =  P_frase_dado_amazon * P_Amazon\n",
    "    lista_probs.append( P_amazon_dado_frase)\n",
    "    \n",
    "    if max(lista_probs) == lista_probs[0]:\n",
    "        dicio_treino[i] = 'Autor'\n",
    "    if max(lista_probs) == lista_probs[1]:\n",
    "        dicio_treino[i] = 'Editora'\n",
    "    if max(lista_probs) == lista_probs[2]:\n",
    "        dicio_treino[i] = 'Amazon'\n",
    "    P_frase_dado_editora = 1\n",
    "    P_frase_dado_amazon = 1\n",
    "    P_frase_dado_autor = 1\n",
    "    \n",
    "    P_autor_dado_frase = 1\n",
    "    \n",
    "    P_editora_dado_frase = 1\n",
    "    \n",
    "    P_amazon_dado_frase =  1\n",
    "    lista_probs = []\n",
    "    i += 1\n",
    "    \n",
    "dicio_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agora, Vamos Verificar a Performance do Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnt_acertos = 0\n",
    "for j in range(313):\n",
    "    \n",
    "    if dicio_treino[j] == train.Target[j]:\n",
    "        qnt_acertos += 1\n",
    "        \n",
    "qnt_acertos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Autor'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Target[61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    elif P_editora_dado_frase >= P_autor_dado_frase and P_editora_dado_frase >= P_amazon_dado_frase:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "if P_autor_dado_frase >= P_editora_dado_frase and P_autor_dado_frase >= P_amazon_dado_frase:\n",
    "        dicio_treino[i] = 'Autor'\n",
    "        \n",
    "    elif P_editora_dado_frase >= P_autor_dado_frase and P_editora_dado_frase >= P_amazon_dado_frase:\n",
    "        dicio_treino[i] = 'Editora'\n",
    "        \n",
    "    elif P_amazon_dado_frase > P_autor_dado_frase and P_amazon_dado_frase > P_editora_dado_frase: \n",
    "        dicio_treino[i] = 'Amazon'\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
