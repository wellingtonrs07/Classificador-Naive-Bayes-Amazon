{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Venâncio Freitas de Araújo Filho\n",
    "\n",
    "Nome: WELLINGTON RODRIGUES DA SILVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\venan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\venan\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Materias 2° semestre Insper\\Ciência de dados\\Projetos\\Projeto 1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Treino: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muito erros grosseiros de tradução. O material...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Primeiramente meu pedido nem veio,Mas me reemb...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Livro com um monte de clichês, mas com pouco c...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sim.adorei o livro Vou continuar a comprar o r...</td>\n",
       "      <td>Editora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Não recebi o livro . Não sei o motivo. Foi fei...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>O livro foi classificado como novo no site e c...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Não gostei porquê a capa veio com um rasgo, o ...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Não consigo entender o alto valor desses e-boo...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>a caixa veio rasgada e amassada, gostaria de u...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Mensagem   Target\n",
       "0    Muito erros grosseiros de tradução. O material...  Editora\n",
       "1    Primeiramente meu pedido nem veio,Mas me reemb...   Amazon\n",
       "2    Livro com um monte de clichês, mas com pouco c...  Editora\n",
       "3    Sim.adorei o livro Vou continuar a comprar o r...  Editora\n",
       "4    Não recebi o livro . Não sei o motivo. Foi fei...   Amazon\n",
       "..                                                 ...      ...\n",
       "293  O livro foi classificado como novo no site e c...   Amazon\n",
       "294  Não gostei porquê a capa veio com um rasgo, o ...   Amazon\n",
       "295  EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...   Amazon\n",
       "296  Não consigo entender o alto valor desses e-boo...   Amazon\n",
       "297  a caixa veio rasgada e amassada, gostaria de u...   Amazon\n",
       "\n",
       "[298 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel('dados_treino.xlsx')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autor      0.377\n",
       "Editora    0.311\n",
       "Amazon     0.311\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Target.value_counts(True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de Teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amontoado de proposições absurdas destinadas a...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quando comprei esse livro fui com uma grande e...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Li um terço do livro. Arrastei-me para procura...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sensacionalista, raso e cheio de distorções ma...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A mensagem do livro da pra entender em 1 págin...</td>\n",
       "      <td>Autor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem Target\n",
       "0  Amontoado de proposições absurdas destinadas a...  Autor\n",
       "1  Quando comprei esse livro fui com uma grande e...  Autor\n",
       "2  Li um terço do livro. Arrastei-me para procura...  Autor\n",
       "3  Sensacionalista, raso e cheio de distorções ma...  Autor\n",
       "4  A mensagem do livro da pra entender em 1 págin...  Autor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel('dados_teste.xlsx')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autor      102\n",
       "Editora     76\n",
       "Amazon      33\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Autor\n",
       "1      Autor\n",
       "2      Autor\n",
       "3      Autor\n",
       "4      Autor\n",
       "       ...  \n",
       "206    Autor\n",
       "207    Autor\n",
       "208    Autor\n",
       "209    Autor\n",
       "210    Autor\n",
       "Name: Target, Length: 211, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu assunto e o que considerou como relevante ou não relevante na classificação dos tweets (Target).\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Vamos Iniciar Extraindo os Dados Referente à cada rótulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função CleanUp 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[´\"!-.:?;$'']' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Clean UP 2: Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steamming(texto): #Recebe lista \n",
    "    stemmed_palavras = []\n",
    "    stemmer = PorterStemmer()\n",
    "    for palavra in texto:\n",
    "        \n",
    "        stemmed_palavras.append(stemmer.stem(palavra)) \n",
    "    \n",
    "    return stemmed_palavras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Clean UP 3: Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords2(texto): #Recebe lista \n",
    "    palavras_sem_stopwords = []\n",
    "    palavras = word_tokenize(' '.join(texto), language='portuguese')\n",
    "\n",
    "    stopwords_pt = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    for palavra in palavras:\n",
    "        if palavra not in stopwords_pt:\n",
    "            palavras_sem_stopwords.append(palavra)\n",
    "    \n",
    "    return palavras_sem_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Clean UP 4:  Remoção de Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(texto): #Recebe lista \n",
    "    texto = ' '.join(texto)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # Símbolos e pictogramas diversos\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # Símbolos alquímicos\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Símbolos de palavras\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Símbolos de árabes estendidos-A\n",
    "                           u\"\\U0001F900-\\U0001F9FF\"  # Símbolos suplementares de árabes estendidos-B\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Símbolos de xadrez\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Símbolos suplementares de xadrez\n",
    "                           u\"\\U0001F004-\\U0001F0CF\"  # Símbolos de domino\n",
    "                           u\"\\U0001F170-\\U0001F251\"  # Símbolos de tai-xi\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # Símbolos e pictogramas diversos\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # Transporte e mapas\n",
    "                           u\"\\U0001F700-\\U0001F77F\"  # Símbolos alquímicos\n",
    "                           u\"\\U0001F780-\\U0001F7FF\"  # Símbolos de palavras\n",
    "                           u\"\\U0001F800-\\U0001F8FF\"  # Símbolos de árabes estendidos-A\n",
    "                           u\"\\U0001FA00-\\U0001FA6F\"  # Símbolos de xadrez\n",
    "                           u\"\\U0001FA70-\\U0001FAFF\"  # Símbolos suplementares de xadrez\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    emoji_pattern = emoji_pattern.sub(r'', texto)\n",
    "    emoji_pattern = emoji_pattern.split(' ')\n",
    "    return emoji_pattern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função 5: Tokenização Por bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texto):\n",
    "    ' '.join(texto)\n",
    "    lista_bigramas = list(bigrams(texto))\n",
    "    return lista_bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciando a extração dos textos referentes aos Rótulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dados do Autor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dados_autor  = train.loc[train.Target == 'Autor' , :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6683,)\n"
     ]
    }
   ],
   "source": [
    "#Montando um Texto\n",
    "texto_comentários_autor = ''\n",
    "for i in dados_autor.Mensagem: \n",
    "    texto_comentários_autor += i\n",
    "    texto_comentários_autor += ' '\n",
    "texto_comentários_autor = cleanup(texto_comentários_autor)\n",
    "texto_comentarios_autor = texto_comentários_autor.lower()\n",
    "texto_comentarios_autor = texto_comentarios_autor.split(' ')\n",
    "texto_comentarios_autor = remove_emojis(texto_comentarios_autor)\n",
    "#texto_comentarios_autor = stopwords2(texto_comentarios_autor)\n",
    "texto_comentarios_autor = steamming(texto_comentarios_autor)\n",
    "#texto_comentarios_autor = tokenize(texto_comentarios_autor)\n",
    "tabela_autor = pd.Series(texto_comentarios_autor )\n",
    "tabela_autor.head()\n",
    "print(tabela_autor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabelas Relativas ao autor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de             256\n",
       "o              237\n",
       "que            223\n",
       "e              202\n",
       "a              196\n",
       "              ... \n",
       "invençõ          1\n",
       "passaria         1\n",
       "praticament      1\n",
       "apontar          1\n",
       "sentimento       1\n",
       "Length: 1848, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequências Absolutas \n",
    "tabela_autor_abs = tabela_autor.value_counts()\n",
    "tabela_autor_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de             0.038306\n",
       "o              0.035463\n",
       "que            0.033368\n",
       "e              0.030226\n",
       "a              0.029328\n",
       "                 ...   \n",
       "invençõ        0.000150\n",
       "passaria       0.000150\n",
       "praticament    0.000150\n",
       "apontar        0.000150\n",
       "sentimento     0.000150\n",
       "Length: 1848, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequências relativas \n",
    "tabela_autor_relativa = tabela_autor.value_counts(True)\n",
    "tabela_autor_relativa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6683"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_autor_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dados da Editora "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_editora = train.loc[train.Target == 'Editora' , :]\n",
    "dados_editora.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        muito\n",
      "1         erro\n",
      "2    grosseiro\n",
      "3           de\n",
      "4     tradução\n",
      "dtype: object\n",
      "(4727,)\n"
     ]
    }
   ],
   "source": [
    "comentarios_editora = dados_editora.Mensagem\n",
    "texto_editora = ''\n",
    "for e in comentarios_editora:\n",
    "    texto_editora += e \n",
    "    texto_editora += ' '\n",
    "texto_editora = cleanup(texto_editora)\n",
    "texto_editora = texto_editora.lower()\n",
    "texto_editora = texto_editora.split(' ')\n",
    "texto_editora = remove_emojis(texto_editora)\n",
    "#texto_editora = stopwords2(texto_editora)\n",
    "texto_editora = steamming(texto_editora)\n",
    "#texto_editora = tokenize(texto_editora)\n",
    "tabela_editora = pd.Series(texto_editora)\n",
    "print(tabela_editora.head())\n",
    "print(tabela_editora.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequências relativas às tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequência absoluta\n",
    "tabela_editora_abs = tabela_editora.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "de           0.041041\n",
       "a            0.033425\n",
       "o            0.029406\n",
       "que          0.028348\n",
       "e            0.027925\n",
       "               ...   \n",
       "avaliação    0.000212\n",
       "reduza       0.000212\n",
       "dezena       0.000212\n",
       "resisti      0.000212\n",
       "frustada     0.000212\n",
       "Length: 1520, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência Relativa \n",
    "tabela_editora_relativa = tabela_editora.value_counts(True)\n",
    "tabela_editora_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4727"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quantidade de palavras \n",
    "tabela_editora_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Dados da Amazon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Mensagem  Target\n",
      "1    Primeiramente meu pedido nem veio,Mas me reemb...  Amazon\n",
      "4    Não recebi o livro . Não sei o motivo. Foi fei...  Amazon\n",
      "7    Pelo amor de Deus!!!! que preço é este......só...  Amazon\n",
      "12   FiZ a compra errada, era pra comprar o livro e...  Amazon\n",
      "23   Não recebi o livro... Acredito que tenham envi...  Amazon\n",
      "..                                                 ...     ...\n",
      "293  O livro foi classificado como novo no site e c...  Amazon\n",
      "294  Não gostei porquê a capa veio com um rasgo, o ...  Amazon\n",
      "295  EU NEM SE QUER RECEBI O PRODUTO! Voces são mui...  Amazon\n",
      "296  Não consigo entender o alto valor desses e-boo...  Amazon\n",
      "297  a caixa veio rasgada e amassada, gostaria de u...  Amazon\n",
      "\n",
      "[90 rows x 2 columns]\n",
      "(90, 2)\n"
     ]
    }
   ],
   "source": [
    "dados_amazon = train.loc[train.Target == 'Amazon' , :]\n",
    "print(dados_amazon)\n",
    "print(dados_amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comentarios_amazon = dados_amazon.Mensagem\n",
    "texto_amazon = ''\n",
    "for texto in comentarios_amazon:\n",
    "    texto_amazon += texto \n",
    "    texto_amazon += ' '\n",
    "texto_amazon = cleanup(texto_amazon)\n",
    "texto_amazon = texto_amazon.lower()\n",
    "texto_amazon = texto_amazon.split(' ')\n",
    "texto_amazon = remove_emojis(texto_amazon)\n",
    "#texto_amazon = stopwords2(texto_amazon)\n",
    "texto_amazon = steamming(texto_amazon)\n",
    "#texto_amazon = tokenize(texto_amazon)\n",
    "tabela_amazon = pd.Series(texto_amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequências referentes à Amazon: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequência absoluta \n",
    "tabela_amazon_abs = tabela_amazon.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "o              0.037732\n",
       "a              0.033468\n",
       "e              0.030484\n",
       "que            0.027499\n",
       "de             0.022170\n",
       "                 ...   \n",
       "cópia          0.000213\n",
       "enviada        0.000213\n",
       "lamppm         0.000213\n",
       "responsável    0.000213\n",
       "otimo          0.000213\n",
       "Length: 1280, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequência relativa\n",
    "tabela_amazon_relativa = tabela_amazon.value_counts(True)\n",
    "tabela_amazon_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4691"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_amazon_abs.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Construindo o Classificador a partir dos testes\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras = texto_editora + texto_amazon + texto_comentarios_autor\n",
    "lista_sem_repeticao = []\n",
    "for palavra in todas_palavras: \n",
    "    if palavra not in lista_sem_repeticao: \n",
    "        lista_sem_repeticao.append(palavra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Probabilidade de Cada Rótulo dentro do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41506738711881247"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Autor = sum(tabela_autor_abs) / len(todas_palavras)\n",
    "P_Autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.291348363455686"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Amazon = sum(tabela_amazon_abs) / len(todas_palavras)\n",
    "P_Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29358424942550154"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_Editora = sum(tabela_editora_abs) / len(todas_palavras)\n",
    "P_Editora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Probabilidade de aparecer em cada frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_frase_dado_autor = 1\n",
    "P_frase_dado_editora = 1\n",
    "P_frase_dado_amazon = 1\n",
    "lista_teste = []\n",
    "i = 0\n",
    "lista_probs = []\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Amazon',\n",
       " 'Autor',\n",
       " 'Autor',\n",
       " 'Editora',\n",
       " 'Autor',\n",
       " 'Autor']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for frase in test.Mensagem:\n",
    "    frase = cleanup(str(frase))\n",
    "    frase = frase.lower()\n",
    "    frase = frase.split(' ')\n",
    "    frase = remove_emojis(frase)\n",
    "    #frase = stopwords2(frase)\n",
    "    frase = steamming(frase)\n",
    "    #frase = tokenize(frase)\n",
    "    for palavras in frase:\n",
    "        \n",
    "        if palavras in texto_comentarios_autor: \n",
    "            P_frase_dado_autor *= (tabela_autor_abs[palavras] + alpha)/ ( (len(lista_sem_repeticao)* alpha) + len(texto_comentarios_autor) )\n",
    "        else: \n",
    "            P_frase_dado_autor *= alpha/(len(texto_comentarios_autor) +(len(lista_sem_repeticao)* alpha))\n",
    "            \n",
    "        \n",
    "        if palavras in texto_amazon: \n",
    "            P_frase_dado_amazon *= (tabela_amazon_abs[palavras] + alpha)/(len(texto_amazon) + (len(lista_sem_repeticao)* alpha))\n",
    "        else: \n",
    "            P_frase_dado_amazon *= alpha/(len(texto_amazon)+(len(lista_sem_repeticao)* alpha))\n",
    "        \n",
    "                \n",
    "        if palavras in texto_editora: \n",
    "            P_frase_dado_editora *= (tabela_editora_abs[palavras] + alpha) / ((len(lista_sem_repeticao)* alpha) + len(texto_editora))\n",
    "        else: \n",
    "            P_frase_dado_editora *= (alpha/ ((len(lista_sem_repeticao)* alpha) + len(texto_editora)))\n",
    "            \n",
    "        \n",
    "            \n",
    "    P_autor_dado_frase = P_frase_dado_autor * P_Autor\n",
    "    lista_probs.append( P_autor_dado_frase)\n",
    "    \n",
    "    P_editora_dado_frase = P_frase_dado_editora * P_Editora\n",
    "    lista_probs.append( P_editora_dado_frase)\n",
    "    \n",
    "    P_amazon_dado_frase =  P_frase_dado_amazon * P_Amazon\n",
    "    lista_probs.append( P_amazon_dado_frase)\n",
    "    \n",
    "    if max(lista_probs) == lista_probs[0]:\n",
    "        lista_teste.append('Autor')\n",
    "    elif max(lista_probs) == lista_probs[1]:\n",
    "        lista_teste.append('Editora')\n",
    "    elif max(lista_probs) == lista_probs[2]:\n",
    "        lista_teste.append('Amazon')\n",
    "        \n",
    "    P_frase_dado_editora = 1\n",
    "    P_frase_dado_amazon = 1\n",
    "    P_frase_dado_autor = 1\n",
    "    \n",
    "    P_autor_dado_frase = 1\n",
    "    \n",
    "    P_editora_dado_frase = 1\n",
    "    \n",
    "    P_amazon_dado_frase =  1\n",
    "    lista_probs = []\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "lista_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agora, Vamos Verificar a Performance do Treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando os verdadeiros positivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Bot</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Editora</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amazon</th>\n",
       "      <td>14.692</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Autor</th>\n",
       "      <td>1.422</td>\n",
       "      <td>44.550</td>\n",
       "      <td>2.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Editora</th>\n",
       "      <td>4.739</td>\n",
       "      <td>21.327</td>\n",
       "      <td>9.953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Bot      Amazon   Autor  Editora\n",
       "Target                          \n",
       "Amazon   14.692   0.474    0.474\n",
       "Autor     1.422  44.550    2.370\n",
       "Editora   4.739  21.327    9.953"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Bot'] = lista_teste\n",
    "tabela_verificação = (pd.crosstab(test.Target , test.Bot , normalize = True )*100).round(3)\n",
    "tabela_verificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando Acertos no Rótulo Autor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando Acertos no Rótulo Editora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando Acertos no Rótulo Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acurácia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agora, Vamos calcular os desvios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
